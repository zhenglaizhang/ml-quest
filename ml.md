
#### unsupervised methods 

* clustering 
* projection methods.

#### predictive modeling 

* classification 
* regression 


> On this particular example, in my case SVM reached 99.2% and was thus the best Model. I gather this is because the test and training sets are drawn randomly from the data.



> The work is in the library and choice of good libraries and training on how to use them well on your project can take you a very long way very quickly.

> Stats is really about small data and understanding the domain (descriptive models). Machine learning, at least in common practice, is leaning towards automation with larger datasets and making predictions (predictive modeling) at the expense of model interpretation/understandability. Prediction performance trumps traditional goals of stats.

> Because of the automation, the focus shifts more toward data quality, problem framing, feature engineering, automatic algorithm tuning and ensemble methods (combining predictive models), with the algorithms themselves taking more of a backseat role.

> Maybe “outliers” are instances that cannot be easily predicted or assigned ambiguous predicted probabilities.

> Instance values can be “fixed” by estimating new values, but whole instance can also be pulled out if data is cheap.
